{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Embedding Map Extraction</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL.Image import open\n",
    "from numpy import array, float32, reshape, expand_dims, argmax\n",
    "from numpy.random import rand\n",
    "from watermarking import extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = extraction.Extraction.extract_key_from_image_file(\"static/data/watermarked_result.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_map = extraction.Extraction().extract_watermark(\n",
    "    array(open(\"static/data/watermarked_result.tif\"), dtype=float32),\n",
    "    key\n",
    ") # size 64 x 64. Perfect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = array(open(\"Watermark.tiff\"), dtype=float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABAAQAAAACCEkxzAAAA3UlEQVR4nG2QsXHDMAxFHyHd2Z21QTyGqkibRZNkFpYpvUF0mUBFCvqO5k9BQs5FYfUO4Af+B4xIkgyYAQy4PcKMAembDwzINzIGlMgDGAF4M+qLDqsDDptDOrRAygCdgcErIBXQ0hlAoNrAnqrrLzlToavmS5t8758rioN2+eCQHM5fVAmf7+1PjDXgxMufFBOptjLNYQbj5NsJWKIYsPT70stuPu4p1GDgn7MwiZM2jHsgs3mcNbQ4sXkOhIPcDpX+UDk7DA5Xq0aZWUa0gJCkla5C4qIggKA2R/ADHvBQgwLJF8UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.TiffImagePlugin.TiffImageFile image mode=1 size=64x64 at 0x20D2ED09748>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(\"Watermark.tiff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow, figure, show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20d2ff77148>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(embedding_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from watermarking import training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing\n",
      "enc   0  ->  64\n",
      "enc   1  ->  32\n",
      "enc   2  ->  16\n",
      "enc   3  ->  8\n",
      "enc   4  ->  4\n",
      "dec   0  ->  64\n",
      "dec   1  ->  32\n",
      "dec   2  ->  16\n",
      "dec   3  ->  8\n",
      "dec   4  ->  4\n"
     ]
    }
   ],
   "source": [
    "train = training.Training(\n",
    "    [[embedding_map]],\n",
    "    [[ground_truth]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FORWARD\n",
      "encoder\n",
      "BN\n",
      "(64, 64, 64)\n",
      "cache:  (64, 64, 64)  for stack  1\n",
      "ReLU\n",
      "Max pool\n",
      "BN\n",
      "(128, 32, 32)\n",
      "cache:  (128, 32, 32)  for stack  2\n",
      "ReLU\n",
      "Max pool\n",
      "BN\n",
      "(256, 16, 16)\n",
      "cache:  (256, 16, 16)  for stack  3\n",
      "ReLU\n",
      "Max pool\n",
      "BN\n",
      "(512, 8, 8)\n",
      "cache:  (512, 8, 8)  for stack  4\n",
      "ReLU\n",
      "Max pool\n",
      "BN\n",
      "(512, 4, 4)\n",
      "cache:  (512, 4, 4)  for stack  5\n",
      "ReLU\n",
      "Max pool\n",
      "decoder\n",
      "Ups\n",
      "BN\n",
      "(512, 4, 4)\n",
      "cache:  (512, 4, 4)  for stack  6\n",
      "Ups\n",
      "BN\n",
      "(256, 8, 8)\n",
      "cache:  (256, 8, 8)  for stack  7\n",
      "Ups\n",
      "BN\n",
      "(128, 16, 16)\n",
      "cache:  (128, 16, 16)  for stack  8\n",
      "Ups\n",
      "BN\n",
      "(64, 32, 32)\n",
      "cache:  (64, 32, 32)  for stack  9\n",
      "Ups\n",
      "BN\n",
      "(1, 64, 64)\n",
      "cache:  (1, 64, 64)  for stack  10\n",
      "BACKWARD\n",
      "Decoder\n",
      "Deriv Cross Entropy\n",
      "shape:  (1, 1, 64, 64)\n",
      "Deriv Softmax\n",
      "shape:  (1, 1, 64, 64)\n",
      "shape:  (1, 2, 64, 64)\n",
      "current stack:  0\n",
      "Deriv BN update weight\n",
      "taking bn cache on  10\n",
      "normalized shape:  (1, 64, 64)\n",
      "derivative scale shift shape:  (1, 2, 64, 64)  and  (1, 64, 64)  resulting gamma grad  (2, 64, 64)\n",
      "error shape:  (2, 64, 64)\n",
      "Deriv BN\n",
      "shape:  (1, 2, 64, 64)\n",
      "Deriv Conv\n",
      "weight grad:  (2, 7, 7)\n",
      "weight grad:  (1, 7, 7)\n",
      "shape:  (1, 1, 64, 64)\n",
      "original structure:  (64, 3)\n",
      "cache:  (1, 64, 32, 32, 2)\n",
      "Deriv Ups\n",
      "shape:  (1, 64, 32, 32)\n",
      "current stack:  1\n",
      "Deriv BN update weight\n",
      "taking bn cache on  9\n",
      "normalized shape:  (64, 32, 32)\n",
      "derivative scale shift shape:  (1, 64, 32, 32)  and  (64, 32, 32)  resulting gamma grad  (64, 32, 32)\n",
      "error shape:  (64, 32, 32)\n",
      "Deriv BN\n",
      "shape:  (1, 64, 32, 32)\n",
      "Deriv Conv\n",
      "weight grad:  (64, 7, 7)\n",
      "weight grad:  (64, 7, 7)\n",
      "shape:  (1, 64, 32, 32)\n",
      "original structure:  (128, 3)\n",
      "cache:  (1, 128, 16, 16, 2)\n",
      "Deriv Ups\n",
      "shape:  (1, 128, 16, 16)\n",
      "current stack:  2\n",
      "Deriv BN update weight\n",
      "taking bn cache on  8\n",
      "normalized shape:  (128, 16, 16)\n",
      "derivative scale shift shape:  (1, 128, 16, 16)  and  (128, 16, 16)  resulting gamma grad  (128, 16, 16)\n",
      "error shape:  (128, 16, 16)\n",
      "Deriv BN\n",
      "shape:  (1, 128, 16, 16)\n",
      "Deriv Conv\n",
      "weight grad:  (128, 7, 7)\n",
      "weight grad:  (128, 7, 7)\n",
      "weight grad:  (128, 7, 7)\n",
      "shape:  (1, 128, 16, 16)\n",
      "original structure:  (256, 3)\n",
      "cache:  (1, 256, 8, 8, 2)\n",
      "Deriv Ups\n",
      "shape:  (1, 256, 8, 8)\n",
      "current stack:  3\n",
      "Deriv BN update weight\n",
      "taking bn cache on  7\n",
      "normalized shape:  (256, 8, 8)\n",
      "derivative scale shift shape:  (1, 256, 8, 8)  and  (256, 8, 8)  resulting gamma grad  (256, 8, 8)\n",
      "error shape:  (256, 8, 8)\n",
      "Deriv BN\n",
      "shape:  (1, 256, 8, 8)\n",
      "Deriv Conv\n",
      "weight grad:  (256, 7, 7)\n",
      "weight grad:  (256, 7, 7)\n",
      "weight grad:  (256, 7, 7)\n",
      "shape:  (1, 256, 8, 8)\n",
      "original structure:  (512, 3)\n",
      "cache:  (1, 512, 4, 4, 2)\n",
      "Deriv Ups\n",
      "shape:  (1, 512, 4, 4)\n",
      "current stack:  4\n",
      "Deriv BN update weight\n",
      "taking bn cache on  6\n",
      "normalized shape:  (512, 4, 4)\n",
      "derivative scale shift shape:  (1, 512, 4, 4)  and  (512, 4, 4)  resulting gamma grad  (512, 4, 4)\n",
      "error shape:  (512, 4, 4)\n",
      "Deriv BN\n",
      "shape:  (1, 512, 4, 4)\n",
      "Deriv Conv\n",
      "weight grad:  (512, 7, 7)\n",
      "weight grad:  (512, 7, 7)\n",
      "weight grad:  (512, 7, 7)\n",
      "shape:  (1, 512, 4, 4)\n",
      "original structure:  (512, 3)\n",
      "cache:  (1, 512, 2, 2, 2)\n",
      "Deriv Ups\n",
      "shape:  (1, 512, 2, 2)\n",
      "Encoder\n",
      "Deriv Max pool\n",
      "original structure:  (512, 3)\n",
      "shape:  (1, 512, 4, 4)\n",
      "Deriv ReLU\n",
      "original structure:  (512, 4, 4)\n",
      "shape:  (1, 512, 4, 4)\n",
      "Deriv BN update weight\n",
      "taking bn cache on  5\n",
      "normalized shape:  (512, 4, 4)\n",
      "derivative scale shift shape:  (1, 512, 4, 4)  and  (512, 4, 4)  resulting gamma grad  (512, 4, 4)\n",
      "error shape:  (512, 4, 4)\n",
      "Deriv BN\n",
      "shape:  (1, 512, 4, 4)\n",
      "Deriv Conv\n",
      "weight grad:  (512, 7, 7)\n",
      "weight grad:  (512, 7, 7)\n",
      "weight grad:  (512, 7, 7)\n",
      "shape:  (1, 512, 4, 4)\n",
      "Deriv Max pool\n",
      "original structure:  (512, 3)\n",
      "shape:  (1, 512, 8, 8)\n",
      "Deriv ReLU\n",
      "original structure:  (512, 8, 8)\n",
      "shape:  (1, 512, 8, 8)\n",
      "Deriv BN update weight\n",
      "taking bn cache on  4\n",
      "normalized shape:  (512, 8, 8)\n",
      "derivative scale shift shape:  (1, 512, 8, 8)  and  (512, 8, 8)  resulting gamma grad  (512, 8, 8)\n",
      "error shape:  (512, 8, 8)\n",
      "Deriv BN\n",
      "shape:  (1, 512, 8, 8)\n",
      "Deriv Conv\n",
      "weight grad:  (512, 7, 7)\n",
      "weight grad:  (512, 7, 7)\n",
      "weight grad:  (512, 7, 7)\n",
      "shape:  (1, 512, 8, 8)\n",
      "Deriv Max pool\n",
      "original structure:  (256, 3)\n",
      "shape:  (1, 256, 16, 16)\n",
      "Deriv ReLU\n",
      "original structure:  (256, 16, 16)\n",
      "shape:  (1, 256, 16, 16)\n",
      "Deriv BN update weight\n",
      "taking bn cache on  3\n",
      "normalized shape:  (256, 16, 16)\n",
      "derivative scale shift shape:  (1, 256, 16, 16)  and  (256, 16, 16)  resulting gamma grad  (256, 16, 16)\n",
      "error shape:  (256, 16, 16)\n",
      "Deriv BN\n",
      "shape:  (1, 256, 16, 16)\n",
      "Deriv Conv\n",
      "weight grad:  (256, 7, 7)\n",
      "weight grad:  (256, 7, 7)\n",
      "weight grad:  (256, 7, 7)\n",
      "shape:  (1, 256, 16, 16)\n",
      "Deriv Max pool\n",
      "original structure:  (128, 3)\n",
      "shape:  (1, 128, 32, 32)\n",
      "Deriv ReLU\n",
      "original structure:  (128, 32, 32)\n",
      "shape:  (1, 128, 32, 32)\n",
      "Deriv BN update weight\n",
      "taking bn cache on  2\n",
      "normalized shape:  (128, 32, 32)\n",
      "derivative scale shift shape:  (1, 128, 32, 32)  and  (128, 32, 32)  resulting gamma grad  (128, 32, 32)\n",
      "error shape:  (128, 32, 32)\n",
      "Deriv BN\n",
      "shape:  (1, 128, 32, 32)\n",
      "Deriv Conv\n",
      "weight grad:  (128, 7, 7)\n",
      "weight grad:  (128, 7, 7)\n",
      "shape:  (1, 128, 32, 32)\n",
      "Deriv Max pool\n",
      "original structure:  (64, 3)\n",
      "shape:  (1, 64, 64, 64)\n",
      "Deriv ReLU\n",
      "original structure:  (64, 64, 64)\n",
      "shape:  (1, 64, 64, 64)\n",
      "Deriv BN update weight\n",
      "taking bn cache on  1\n",
      "normalized shape:  (64, 64, 64)\n",
      "derivative scale shift shape:  (1, 64, 64, 64)  and  (64, 64, 64)  resulting gamma grad  (64, 64, 64)\n",
      "error shape:  (64, 64, 64)\n",
      "Deriv BN\n",
      "shape:  (1, 64, 64, 64)\n",
      "Deriv Conv\n",
      "weight grad:  (64, 7, 7)\n",
      "weight grad:  (64, 7, 7)\n",
      "shape:  (1, 64, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "result, cache, loss = train.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(cache[3][0][4]))\n",
    "print(cache[3][0][4][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(result[0][0]))j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = expand_dims(ground_truth, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "fig= figure(figsize=(8, 8))\n",
    "columns = 8\n",
    "rows = 8\n",
    "for i in range(1, columns*rows +1):\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    imshow(result[0][j])\n",
    "    j += 1\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>(The real) Training</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = training.Training(\n",
    "    [embedding_map, embedding_map],\n",
    "    [ground_truth, ground_truth]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax, loss = train.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(softmax[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Check NC of forward only</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from watermarking import embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embedding.Embedding.normalized_correlation_coef(softmax[0], ground_truth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Try to classify softmax better</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified = []\n",
    "for row in softmax[0]:\n",
    "    new_row = []\n",
    "    for pixel in row:\n",
    "        if pixel > 1:\n",
    "            pixel = 1\n",
    "        elif pixel < 0:\n",
    "            pixel = 0\n",
    "        else:\n",
    "            pixel = round(pixel)\n",
    "        new_row.append(pixel)\n",
    "    classified.append(new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embedding.Embedding.normalized_correlation_coef(classified, ground_truth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Try displaying the classified result</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL.Image import fromarray\n",
    "from numpy import uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tes = fromarray(array(classified, dtype=uint8) * 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>...Okay. At least not all of them is black/white :)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, kernel_size=(7, 7), padding='same', input_shape=(1, 64, 64), activation='relu'),\n",
    "    tf.keras.layers.Conv2D(64, kernel_size=(7, 7), padding='same', activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(epsilon=0.001),\n",
    "    tf.keras.layers.Conv2D(1, kernel_size=(7, 7), padding='same'),\n",
    "    tf.keras.layers.Conv2D(1, kernel_size=(7, 7), padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(epsilon=0.001),\n",
    "    tf.keras.layers.Activation('softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(1, kernel_size=(3, 3), padding='same', input_shape=(64, 64, 64)),\n",
    "    tf.keras.layers.Conv2D(1, kernel_size=(3, 3), padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(epsilon=0.001),\n",
    "    tf.keras.layers.Conv2D(1, kernel_size=(3, 3), padding='same', activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.SGD(lr=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    x=result,\n",
    "    y=ground_truth,\n",
    "    epochs=1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.predict_proba(expand_dims(rand(64, 64, 64), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.reshape((64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized = []\n",
    "for row in result[0][0]:\n",
    "    new_row = []\n",
    "    for px in row:\n",
    "        if px < 0 or px > 1 - px:\n",
    "            new_row.append(0)\n",
    "        else:\n",
    "            new_row.append(1)\n",
    "    normalized.append(new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(array(normalized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
