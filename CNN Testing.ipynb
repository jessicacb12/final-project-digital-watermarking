{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Embedding Map Extraction</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from PIL.Image import open\n",
    "from numpy import array, float32, reshape, expand_dims, argmax\n",
    "from numpy.random import rand\n",
    "from watermarking import extraction, cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = array(open(\"Watermark.tiff\"), dtype=float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from watermarking import extraction, process, forward, cnn, attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = open(\"static/training/airplane.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "attacked = attacks.Attacks(process.Process.pil_to_open_cv(image)).do_transformation(attacks.Attacks.MEDIAN_BLUR, 5)\n",
    "attacked2 = attacks.Attacks(process.Process.pil_to_open_cv(image)).do_transformation(attacks.Attacks.GAUSSIAN_BLUR, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = extraction.Extraction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = ext.extract_key_from_pil_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = ext.get_embedding_map(process.Process.pil_to_open_cv(image), key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219.00000000000003"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array(result).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2823344e130>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 34.,  34.,  34., ..., 212., 212., 212.],\n",
       "       [ 34.,  34.,  34., ..., 206., 206., 206.],\n",
       "       [ 34.,  34.,  34., ..., 184., 184., 183.],\n",
       "       ...,\n",
       "       [ 74.,  74.,  74., ...,  74.,  74.,  74.],\n",
       "       [ 74.,  74.,  74., ...,  74.,  74.,  74.],\n",
       "       [ 74.,  74.,  74., ...,  74.,  74.,  74.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_image = []\n",
    "for row in result:\n",
    "    norm_row = []\n",
    "    for _px in row:\n",
    "        norm_row.append(float(round(_px)))\n",
    "    norm_image.append(norm_row)\n",
    "# norm_image2 = []\n",
    "# for row in attacked:\n",
    "#     norm_row = []\n",
    "#     for _px in row:\n",
    "#         norm_row.append(float(round(_px)))\n",
    "#     norm_image2.append(norm_row)\n",
    "# norm_image3 = []\n",
    "# for row in attacked2:\n",
    "#     norm_row = []\n",
    "#     for _px in row:\n",
    "#         norm_row.append(float(round(_px)))\n",
    "#     norm_image3.append(norm_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing\n",
      "enc   0  ->  64\n",
      "dec   0  ->  64\n",
      " (1, 1, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "f = forward.Forward(\n",
    "    False,\n",
    "    [\n",
    "        [norm_image]\n",
    "    ], # double array as batch and channel\n",
    "    cnn.CNN.init_params()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder\n",
      "shape:  (1, 1, 64, 64)\n",
      "STACK: 0\n",
      "conv per stack:  (1, 64, 64, 1)\n",
      "WARNING:tensorflow:Layer conv2d is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "(1, 64, 64, 8)\n",
      "(1, 64, 64, 8)\n",
      "ReLU and max pool\n",
      "decoder\n",
      "shape:  (1, 8, 32, 32)\n",
      "STACK: 0\n",
      "ups and conv\n",
      "WARNING:tensorflow:Layer up_sampling2d is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "ups:  (8, 64, 64)\n",
      "conv per stack:  (1, 64, 64, 8)\n",
      "WARNING:tensorflow:Layer conv2d_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "(1, 64, 64, 1)\n",
      "(1, 64, 64, 1)\n",
      "decoded:  (1, 1, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "result = f.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array(result).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x28232db4250>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(result, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conved_images = []\n",
    "for batch, image in enumerate([[norm_image]]):\n",
    "    conved_images.append(\n",
    "        f.conv_per_stack(\n",
    "            array(image), f.ENCODER, 0, batch\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array(conved_images).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(50, 50))\n",
    "for i in range(len(conved_images[0])):\n",
    "    sub = fig.add_subplot(2, 16, i + 1)\n",
    "    sub.imshow(conved_images[0][i], interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conved_images = array(conved_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conved_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_conv = []\n",
    "for batch, image in enumerate(conved_images):\n",
    "    image = f.relu_per_stack(image, batch)\n",
    "    image = f.max_pooling_per_stack(image, batch)\n",
    "    processed_conv.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_conv = array(processed_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_conv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(50, 50))\n",
    "for i in range(len(processed_conv[0])):\n",
    "    sub = fig.add_subplot(2, 16, i + 1)\n",
    "    sub.imshow(processed_conv[0][i], interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = []\n",
    "for batch, image in enumerate(processed_conv):\n",
    "    image = f.upsample_per_stack(\n",
    "        image, batch, 0\n",
    "    )\n",
    "    processed.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(50, 50))\n",
    "for i in range(len(processed[0])):\n",
    "    sub = fig.add_subplot(2, 16, i + 1)\n",
    "    sub.imshow(processed[0][i], interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = []\n",
    "for batch, image in enumerate(processed):\n",
    "    image = f.conv_per_stack(\n",
    "        array(image), f.DECODER, 0, batch\n",
    "    )\n",
    "    decoded.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(decoded[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sm = f.softmax_per_batch(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from watermarking import training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train = training.Training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "epoch = 10\n",
    "losses = []\n",
    "accs = []\n",
    "for i in range(0, epoch):\n",
    "    print('EPOCH: ', i)\n",
    "    result, loss, acc, attacked_wm = train.auto_training()\n",
    "    losses.append(loss)\n",
    "    accs.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.store_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ground_truth = array(ground_truth)\n",
    "max_result = -1\n",
    "chosen_img = None\n",
    "for data in sm:\n",
    "    background, foreground = data\n",
    "    classified = []\n",
    "    for i, row in enumerate(background):\n",
    "        new_row = []\n",
    "        for j, _px in enumerate(row):\n",
    "            new_row.append(\n",
    "                0 if _px > foreground[i][j] else 255\n",
    "            )\n",
    "        classified.append(new_row)\n",
    "    classified = array(classified)\n",
    "    a = ground_truth.ravel()\n",
    "    b = classified.ravel()\n",
    "    \n",
    "    a = (a - np.mean(a)) / (np.std(a) * len(a))\n",
    "    b = (b - np.mean(b)) / (np.std(b))\n",
    "    c = np.correlate(a, b, 'full')\n",
    "    \n",
    "    if c.max() > max_result:\n",
    "        max_result = c.max()\n",
    "        chosen_img = classified\n",
    "    print(c.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(result[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(cnn.CNN.softmax_classifier(result[0][0], result[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(chosen_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(result))\n",
    "print(max_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ground_truth.ravel()\n",
    "b = array(result).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (a - np.mean(a)) / (np.std(a) * len(a))\n",
    "b = (b - np.mean(b)) / (np.std(b))\n",
    "c = np.correlate(a, b, 'full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.872566874659116"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array(sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Create Graph from Result</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Attacks</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = array(accs) # epoch, image, attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Check NC of forward only</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from watermarking import embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embedding.Embedding.normalized_correlation_coef(softmax[0], ground_truth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Try to classify softmax better</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified = []\n",
    "for row in softmax[0]:\n",
    "    new_row = []\n",
    "    for pixel in row:\n",
    "        if pixel > 1:\n",
    "            pixel = 1\n",
    "        elif pixel < 0:\n",
    "            pixel = 0\n",
    "        else:\n",
    "            pixel = round(pixel)\n",
    "        new_row.append(pixel)\n",
    "    classified.append(new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embedding.Embedding.normalized_correlation_coef(classified, ground_truth))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
