{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL.Image import open\n",
    "from numpy import array, float32, reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from watermarking import training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import sub, search\n",
    "from os import listdir\n",
    "from numpy import expand_dims, uint8, mean, asarray, flip\n",
    "from watermarking import embedding, process, extraction, cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Change Watermark to One-Hot</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WM_to_one_hot(wm):\n",
    "    one_hot = []\n",
    "    for row in wm:\n",
    "        new_row = []\n",
    "        for _px in row:\n",
    "            new_row.append(\n",
    "                [0, 1] if _px == 0 else [1, 0]\n",
    "            )\n",
    "        one_hot.append(new_row)\n",
    "    return array(one_hot)\n",
    "\n",
    "def WMs_to_one_hot(wms):\n",
    "    one_hot_wms = []\n",
    "    for wm in wms:\n",
    "        one_hot_wms.append(WM_to_one_hot(wm))\n",
    "    return array(one_hot_wms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = training.Training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attacked_watermarks = WMs_to_one_hot(\n",
    "    train.normalize_watermark(\n",
    "        train.apply_transformations(\n",
    "            open(\"Watermark.tiff\"), iswatermark=True\n",
    "        )\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = train.normalize_watermark(\n",
    "    train.apply_transformations(\n",
    "        open(\"Watermark.tiff\"), iswatermark=True\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watermark = open(\"Watermark.tiff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load Training Images</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label(wms, total_img):\n",
    "    label = []\n",
    "    attack_i = 0\n",
    "    for i in range(total_img):\n",
    "        label.append(wms[0])\n",
    "        attack_i += 1\n",
    "        if attack_i == 24:\n",
    "            attack_i = 0\n",
    "    return array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_dataset(prepath, processing_path):\n",
    "    images_filename = listdir(prepath)\n",
    "    datasets = []\n",
    "    for filename in images_filename:\n",
    "        image = open(prepath + \"/\" + filename)\n",
    "        full_path = processing_path + \"/\" + sub(\n",
    "            search(\".tif+$\", filename).group(), \"\", filename\n",
    "        )\n",
    "        embedding.Embedding().embed_watermark(\n",
    "            process.Process.pil_to_open_cv(\n",
    "                image\n",
    "            ),\n",
    "            array(watermark, dtype=uint8),\n",
    "            full_path\n",
    "        )\n",
    "        image = open(full_path + \".tif\")\n",
    "        datasets.extend(\n",
    "            expand_dims(\n",
    "                train.normalize_embedding_maps(\n",
    "                    train.get_embedding_maps(                   \n",
    "                        train.apply_transformations(image),\n",
    "                        extraction.Extraction().extract_key_from_pil_image(image)\n",
    "                    )\n",
    "                ), axis=3\n",
    "            )\n",
    "        )\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_imgs = create_dataset(train.PRE_TRAINING_PATH, train.TRAINING_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_imgs = create_dataset(\n",
    "    'static/test',\n",
    "    'static/testing'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = array(train_imgs)\n",
    "test_imgs = array(test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = create_label(attacked_watermarks, train_imgs.shape[0])\n",
    "test_label = create_label(attacked_watermarks, test_imgs.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Model</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Original Model</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    # encoder\n",
    "\n",
    "    #layer 1\n",
    "    tf.keras.layers.Conv2D(\n",
    "        64, 7, input_shape=(64, 64, 1), activation='relu', padding = 'same', kernel_initializer = 'random_normal', use_bias=False\n",
    "    ),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        64, 7, activation='relu', padding = 'same', kernel_initializer = 'random_normal', use_bias=False\n",
    "    ),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "\n",
    "    #layer 2\n",
    "    tf.keras.layers.Conv2D(\n",
    "        128, 7, activation='relu', padding = 'same', kernel_initializer = 'random_normal', use_bias=False\n",
    "    ),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        128, 7, activation='relu', padding = 'same', kernel_initializer = 'random_normal', use_bias=False\n",
    "    ),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "\n",
    "    #layer 3\n",
    "    tf.keras.layers.Conv2D(\n",
    "        256, 7, activation='relu', padding = 'same', kernel_initializer = 'random_normal', use_bias=False\n",
    "    ),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        256, 7, activation='relu', padding = 'same', kernel_initializer = 'random_normal', use_bias=False\n",
    "    ),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        256, 7, activation='relu', padding = 'same', kernel_initializer = 'random_normal', use_bias=False\n",
    "    ),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "\n",
    "    #layer 4\n",
    "    tf.keras.layers.Conv2D(\n",
    "        512, 7, activation='relu', padding = 'same', kernel_initializer = 'random_normal', use_bias=False\n",
    "    ),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        512, 7, activation='relu', padding = 'same', kernel_initializer = 'random_normal', use_bias=False\n",
    "    ),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        512, 7, activation='relu', padding = 'same', kernel_initializer = 'random_normal', use_bias=False\n",
    "    ),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "\n",
    "    #layer 5\n",
    "    tf.keras.layers.Conv2D(\n",
    "        512, 7, activation='relu', padding = 'same', kernel_initializer = 'random_normal', use_bias=False\n",
    "    ),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        512, 7, activation='relu', padding = 'same', kernel_initializer = 'random_normal', use_bias=False\n",
    "    ),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        512, 7, activation='relu', padding = 'same', kernel_initializer = 'random_normal', use_bias=False\n",
    "    ),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    # decoder\n",
    "\n",
    "    # layer 1\n",
    "    tf.keras.layers.UpSampling2D(),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        512, 7, activation='relu', padding = 'same', kernel_initializer = 'random_normal', use_bias=False\n",
    "    ),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        512, 7, activation='relu', padding = 'same', kernel_initializer = 'random_normal', use_bias=False\n",
    "    ),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        512, 7, activation='relu', padding = 'same', kernel_initializer = 'random_normal', use_bias=False\n",
    "    ),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    # layer 2\n",
    "    tf.keras.layers.UpSampling2D(),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        512, 7, activation='relu', padding = 'same', kernel_initializer = 'random_normal', use_bias=False\n",
    "    ),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        512, 7, activation='relu', padding = 'same', kernel_initializer = 'random_normal', use_bias=False\n",
    "    ),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        512, 7, activation='relu', padding = 'same', kernel_initializer = 'random_normal', use_bias=False\n",
    "    ),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    # layer 3\n",
    "    tf.keras.layers.UpSampling2D(),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        256, 7, activation='relu', padding = 'same', kernel_initializer = 'random_normal', use_bias=False\n",
    "    ),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        256, 7, activation='relu', padding = 'same', kernel_initializer = 'random_normal', use_bias=False\n",
    "    ),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        256, 7, activation='relu', padding = 'same', kernel_initializer = 'random_normal', use_bias=False\n",
    "    ),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    # layer 4\n",
    "    tf.keras.layers.UpSampling2D(),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        128, 7, activation='relu', padding = 'same', kernel_initializer = 'random_normal', use_bias=False\n",
    "    ),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        128, 7, activation='relu', padding = 'same', kernel_initializer = 'random_normal', use_bias=False\n",
    "    ),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    # layer 5\n",
    "    tf.keras.layers.UpSampling2D(),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        64, 7, activation='relu', padding = 'same', kernel_initializer = 'random_normal', use_bias=False\n",
    "    ),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        64, 7, activation='relu', padding = 'same', kernel_initializer = 'random_normal', use_bias=False\n",
    "    ),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "\n",
    "    tf.keras.layers.Conv2D(\n",
    "        2, 7, activation = 'softmax', padding= 'same', kernel_initializer = 'random_normal', use_bias=False\n",
    "    )\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>My Model</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    # encoder\n",
    "    tf.keras.layers.Conv2D(\n",
    "        4, 7, input_shape=(64, 64, 1), activation='relu', padding = 'same', kernel_initializer = 'random_normal', use_bias=False\n",
    "    ),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        4, 7, activation='relu', padding = 'same', kernel_initializer = 'random_normal', use_bias=False\n",
    "    ),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "\n",
    "    tf.keras.layers.Conv2D(\n",
    "        8, 7, input_shape=(64, 64, 1), activation='relu', padding = 'same', kernel_initializer = 'random_normal', use_bias=False\n",
    "    ),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        8, 7, activation='relu', padding = 'same', kernel_initializer = 'random_normal', use_bias=False\n",
    "    ),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    # decoder\n",
    "    tf.keras.layers.UpSampling2D(),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        8, 7, activation='relu', padding = 'same', kernel_initializer = 'random_normal', use_bias=False\n",
    "    ),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        8, 7, activation='relu', padding = 'same', kernel_initializer = 'random_normal', use_bias=False\n",
    "    ),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    tf.keras.layers.UpSampling2D(),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        4, 7, activation='relu', padding = 'same', kernel_initializer = 'random_normal', use_bias=False\n",
    "    ),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        4, 7, activation='relu', padding = 'same', kernel_initializer = 'random_normal', use_bias=False\n",
    "    ),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        2, 7, activation = 'softmax', padding= 'same', kernel_initializer = 'random_normal', use_bias=False\n",
    "    )\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 64, 64, 64)        3136      \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 64, 64, 64)        200704    \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 64, 64, 64)        256       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 32, 32, 64)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 32, 32, 128)       401408    \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 32, 32, 128)       802816    \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 32, 32, 128)       512       \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 16, 16, 128)       0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 16, 16, 256)       1605632   \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 16, 16, 256)       3211264   \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 16, 16, 256)       3211264   \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 16, 16, 256)       1024      \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 8, 8, 256)         0         \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, 8, 8, 512)         6422528   \n_________________________________________________________________\nconv2d_8 (Conv2D)            (None, 8, 8, 512)         12845056  \n_________________________________________________________________\nconv2d_9 (Conv2D)            (None, 8, 8, 512)         12845056  \n_________________________________________________________________\nbatch_normalization_3 (Batch (None, 8, 8, 512)         2048      \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 4, 4, 512)         0         \n_________________________________________________________________\nconv2d_10 (Conv2D)           (None, 4, 4, 512)         12845056  \n_________________________________________________________________\nconv2d_11 (Conv2D)           (None, 4, 4, 512)         12845056  \n_________________________________________________________________\nconv2d_12 (Conv2D)           (None, 4, 4, 512)         12845056  \n_________________________________________________________________\nbatch_normalization_4 (Batch (None, 4, 4, 512)         2048      \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 2, 2, 512)         0         \n_________________________________________________________________\nup_sampling2d (UpSampling2D) (None, 4, 4, 512)         0         \n_________________________________________________________________\nconv2d_13 (Conv2D)           (None, 4, 4, 512)         12845056  \n_________________________________________________________________\nconv2d_14 (Conv2D)           (None, 4, 4, 512)         12845056  \n_________________________________________________________________\nconv2d_15 (Conv2D)           (None, 4, 4, 512)         12845056  \n_________________________________________________________________\nbatch_normalization_5 (Batch (None, 4, 4, 512)         2048      \n_________________________________________________________________\nup_sampling2d_1 (UpSampling2 (None, 8, 8, 512)         0         \n_________________________________________________________________\nconv2d_16 (Conv2D)           (None, 8, 8, 512)         12845056  \n_________________________________________________________________\nconv2d_17 (Conv2D)           (None, 8, 8, 512)         12845056  \n_________________________________________________________________\nconv2d_18 (Conv2D)           (None, 8, 8, 512)         12845056  \n_________________________________________________________________\nbatch_normalization_6 (Batch (None, 8, 8, 512)         2048      \n_________________________________________________________________\nup_sampling2d_2 (UpSampling2 (None, 16, 16, 512)       0         \n_________________________________________________________________\nconv2d_19 (Conv2D)           (None, 16, 16, 256)       6422528   \n_________________________________________________________________\nconv2d_20 (Conv2D)           (None, 16, 16, 256)       3211264   \n_________________________________________________________________\nconv2d_21 (Conv2D)           (None, 16, 16, 256)       3211264   \n_________________________________________________________________\nbatch_normalization_7 (Batch (None, 16, 16, 256)       1024      \n_________________________________________________________________\nup_sampling2d_3 (UpSampling2 (None, 32, 32, 256)       0         \n_________________________________________________________________\nconv2d_22 (Conv2D)           (None, 32, 32, 128)       1605632   \n_________________________________________________________________\nconv2d_23 (Conv2D)           (None, 32, 32, 128)       802816    \n_________________________________________________________________\nbatch_normalization_8 (Batch (None, 32, 32, 128)       512       \n_________________________________________________________________\nup_sampling2d_4 (UpSampling2 (None, 64, 64, 128)       0         \n_________________________________________________________________\nconv2d_24 (Conv2D)           (None, 64, 64, 64)        401408    \n_________________________________________________________________\nconv2d_25 (Conv2D)           (None, 64, 64, 64)        200704    \n_________________________________________________________________\nbatch_normalization_9 (Batch (None, 64, 64, 64)        256       \n_________________________________________________________________\nconv2d_26 (Conv2D)           (None, 64, 64, 2)         6272      \n=================================================================\nTotal params: 173,028,032\nTrainable params: 173,022,144\nNon-trainable params: 5,888\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "history = model.fit(\n",
    "    train_imgs,\n",
    "    train_label,\n",
    "    validation_data=(test_imgs, test_label),\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig('static/layer-channel-test/4488batch-64-acc2-0.01.png')\n",
    "plt.show()\n",
    "plt.close()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.savefig('static/layer-channel-test/4488batch-64-loss2-0.01.png')\n",
    "plt.show()\n",
    "plt.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = open(\"static/training/bird.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = extraction.Extraction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = ext.extract_key_from_pil_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em = expand_dims(ext.get_embedding_map(process.Process.pil_to_open_cv(image), key), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "result = model.predict(expand_dims(em, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified = []\n",
    "for row in result[0]:\n",
    "    new_row = []\n",
    "    for _px in row:\n",
    "        new_row.append(\n",
    "            255 if _px[0] > _px[1] else 0\n",
    "        )\n",
    "    classified.append(new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(classified, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction.Extraction.normalized_correlation_coef(classified, watermark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NC\n",
    "88:11 = 0.9119992164191522, 26 min, 195ms, 4,103 params <br>\n",
    "88:88 = 0.9683892396583422, 38min 46s, 201ms, 10,648 params <br>\n",
    "4488:8844 = 0.9580494917931204, 377ms, 14,796 params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dict = dict([(layer.name, layer) for layer in model.layers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Change Weight Shape</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = layer_dict['conv2d_7'].weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weight[0].numpy().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "param_dict = {\n",
    "    'dec0-gamma': [weight[0].numpy().tolist()],\n",
    "    'dec0-beta': [weight[1].numpy().tolist()],\n",
    "    'dec0-average': [weight[2].numpy().tolist()],\n",
    "    'dec0-variance': [weight[3].numpy().tolist()],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = weight[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_shape(weight):\n",
    "    \"\"\"7718 -> 8177\"\"\"\n",
    "    ch_number = weight.shape[3]\n",
    "    input_number = weight.shape[2]\n",
    "    new_weight = []\n",
    "    for i in range(ch_number):\n",
    "        new_channel = []\n",
    "        for j in range(input_number):\n",
    "            new_input = []\n",
    "            for row in weight:\n",
    "                new_row = []\n",
    "                for _px in row:\n",
    "                    new_row.append(_px[j][i])\n",
    "                new_input.append(new_row)\n",
    "            new_channel.append(new_input)\n",
    "        new_weight.append(new_channel)\n",
    "    return new_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_reverse_shape(weight):\n",
    "    \"\"\"877 -> 778\"\"\"\n",
    "    (i_number, w, h) = weight.shape\n",
    "    new_weight = np.zeros((w, h, i_number))\n",
    "    for i in range(i_number):\n",
    "        for j in range(w):\n",
    "            for k in range(h):\n",
    "                new_weight[j, k, i] = weight[i, j, k]\n",
    "    return new_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reversed_weight = array(reverse_shape(weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reversed_weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_param_dict(weight, prefix):\n",
    "    param = {}\n",
    "    for i, channel in enumerate(weight):\n",
    "        for j, matrix in enumerate(channel):\n",
    "            param[prefix + '-' + str(i) + '-' + str(j)] = matrix\n",
    "    return param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_softmax_param_dict(weight):\n",
    "    params = ['fg', 'bg']\n",
    "    param_dict = {}\n",
    "    for i, param in enumerate(params):\n",
    "        for j, kernel in enumerate(weight[i]):\n",
    "            param_dict['softmax-' + param + str(j)] = kernel\n",
    "    return param_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = create_param_dict(reversed_weight, 'dec0-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "param_dict = create_softmax_param_dict(reversed_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.CNN.store_param(param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Get Visualization Model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = [layer.output for layer in model.layers[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization_model = tf.keras.models.Model(inputs = model.input, outputs = outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_maps = visualization_model.predict(array([train_imgs[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(array(train_imgs[0]).reshape((64, 64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array(train_imgs[0]).reshape((64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_shape_fm(feature_map):\n",
    "    ch_number = feature_map.shape[2]\n",
    "    new_fm = []\n",
    "    for i in range(ch_number):\n",
    "        new_channel = []\n",
    "        for row in feature_map:\n",
    "            new_row = []\n",
    "            for _px in row:\n",
    "                new_row.append(_px[i])\n",
    "            new_channel.append(new_row)\n",
    "        new_fm.append(new_channel)\n",
    "    return new_fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array(feature_maps[6]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(feature_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reversed_fm = reverse_shape_fm(feature_maps[6][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "array(reversed_fm).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = figure(figsize=(50, 50))\n",
    "for i in range(len(reversed_fm)):\n",
    "    sub = fig.add_subplot(2, 16, i + 1)\n",
    "    sub.imshow(reversed_fm[i], interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = figure(figsize=(50, 50))\n",
    "for i in range(len(reversed_fm)):\n",
    "    sub = fig.add_subplot(2, 16, i + 1)\n",
    "    sub.imshow(reversed_fm[i], interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = figure(figsize=(50, 50))\n",
    "for i in range(len(reversed_fm)):\n",
    "    sub = fig.add_subplot(2, 16, i + 1)\n",
    "    sub.imshow(reversed_fm[i], interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = figure(figsize=(50, 50))\n",
    "for i in range(len(reversed_fm)):\n",
    "    sub = fig.add_subplot(2, 16, i + 1)\n",
    "    sub.imshow(reversed_fm[i], interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = figure(figsize=(50, 50))\n",
    "for i in range(len(reversed_fm)):\n",
    "    sub = fig.add_subplot(2, 16, i + 1)\n",
    "    sub.imshow(reversed_fm[i], interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = figure(figsize=(50, 50))\n",
    "for i in range(len(reversed_fm)):\n",
    "    sub = fig.add_subplot(2, 16, i + 1)\n",
    "    sub.imshow(reversed_fm[i], interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.keras.layers.Conv2D(\n",
    "    8, 7, input_shape=(64, 64, 1), padding = 'same', kernel_initializer=tes, use_bias=False\n",
    ")(array([train_imgs[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tes(shape, dtype=None):\n",
    "    w = layer_dict['conv2d'].weights[0].numpy()\n",
    "    print(w.shape)\n",
    "#     w[tuple(map(lambda x: int(np.floor(x/2)), w.shape))]=1\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(reverse_shape_fm(a[0])[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.layers.UpSampling2D()(a.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}